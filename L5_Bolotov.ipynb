{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Лабораторная работа №4\n",
    "Импорт и архивирование текста из пдф с веб страницы\n",
    "Болотов М.В. АСУ4-22-1м"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os                                          # Для работы с файловой системой.\n",
    "import fitz                                        # Из PyMuPDF для работы с PDF-файлами.\n",
    "import zipfile                                     # Для создания ZIP-архива.\n",
    "import requests                                    # Для выполнения HTTP-запросов.\n",
    "from bs4 import BeautifulSoup                      # Для парсинга веб-страниц.\n",
    "from urllib.parse import urljoin                   # Объединение относительных URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_filename(filename):                                                          # Очистки имени файла от специальных символов\n",
    "    return \"\".join(c if c.isalnum() or c in ('.', '_', '-') else '_' for c in filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_pdf_links(url):                                                                # Функция для извлечения PDF-ссылок с заданной веб-страницы\n",
    "    response = requests.get(url)                                                       # Отправка HTTP-запроса по URL.\n",
    "    if not response.ok:\n",
    "        return []                                                                     \n",
    "\n",
    "    soup = BeautifulSoup(response.text, 'html.parser')                                 # Парсинг HTML-кода страницы\n",
    "    pdf_links = []                                                                     # Пустой список для хранения PDF-ссылок.\n",
    "    base_url = 'https://pstu.ru/sveden/education/'                                     # Базовый URL\n",
    "    for a in soup.find_all('a', href=True):                                            \n",
    "        link = a['href']                                                               # Получение значения атрибута href\n",
    "        full_pdf_url = urljoin(base_url, link)                                         # Создание полного URL с помощью urljoin\n",
    "        if full_pdf_url.endswith('.pdf'):                                              # Проверка, заканчивается ли ссылка на .pdf\n",
    "            pdf_links.append(full_pdf_url)                                             # Добавление полной PDF-ссылки в список\n",
    "    return pdf_links                                                                   # Список полных PDF-ссылок"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_pdf(pdf_url):                                                    # Определение функции для извлечения текста из PDF-файла по его URL\n",
    "    response = requests.get(pdf_url)                                                   # Отправка HTTP-запроса GET для загрузки PDF.\n",
    "    if not response.ok:\n",
    "        return None                                                                    # если запрос не удался\n",
    "\n",
    "    pdf_data = response.content  \n",
    "    pdf_document = fitz.open(\"pdf\", pdf_data)                                          # Открытие PDF-документа с использованием PyMuPDF.\n",
    "    \n",
    "    text = \"\"                                                                          # пустая строка для хранения извлеченного текста\n",
    "    for page_num in range(len(pdf_document)):                                          # Цикл перебор страниц в PDF\n",
    "        page = pdf_document.load_page(page_num)  \n",
    "        text += page.get_text()                                                        # Извлечение текста с страницы и добавление в результат.\n",
    "\n",
    "    return text  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf_text(url, output_folder):                                             # Определение функции для загрузки PDF, извлечения текста и создания ZIP-архива.\n",
    "    if not os.path.exists(output_folder):                                              # Проверка существования выходной папки.\n",
    "        os.makedirs(output_folder)                                                     # если отсутствует, создание выходной папки.\n",
    "\n",
    "    output_zip_filename = os.path.join(output_folder, \"pdf_texts.zip\")                 # Определение пути к ZIP-файлу\n",
    "\n",
    "    with zipfile.ZipFile(output_zip_filename, 'w', zipfile.ZIP_DEFLATED) as zipf:\n",
    "\n",
    "        visited_urls = set()\n",
    "\n",
    "        def crawl_and_extract(base_url, url):                                          # Определение рекурсивной функции для обхода и извлечения PDF-файлов.\n",
    "            visited_urls.add(url)                                                      # Отметка текущего URL как посещенного.\n",
    "            pdf_links = get_pdf_links(url)                                             # Получение полных PDF-ссылок с текущего URL\n",
    "            \n",
    "            for pdf_link in pdf_links:                                                 # Перебор PDF-ссылок и извлечение текста\n",
    "                if pdf_link not in visited_urls:                                       # Проверка, не посещена ли PDF-ссылка\n",
    "                    text = extract_text_from_pdf(pdf_link)                             # Извлечение текста из PDF.\n",
    "                    if text:                                                           # Если текст был успешно извлечен.\n",
    "                        pdf_filename = os.path.basename(pdf_link)                      # Получение имени PDF-файла.\n",
    "                        txt_filename = pdf_filename.replace('.pdf', '.txt')            # Генерация имени соответствующего TXT-файла\n",
    "                        zipf.writestr(txt_filename, text.encode('utf-8'))              # Запись текста в ZIP-файл.\n",
    "                    visited_urls.add(pdf_link)                                         # Отметка PDF-ссылки как посещенной.\n",
    "            \n",
    "            for link in get_pdf_links(url):                                            # Рекурсивное обход дочерних ссылок, найденных на текущей странице\n",
    "                if link not in visited_urls:                                           # Проверка, не посещена ли дочерняя ссылка.\n",
    "                    full_child_url = urljoin(base_url, link)                           # Создание полного URL дочерней ссылки\n",
    "                    crawl_and_extract(base_url, full_child_url)                        # Рекурсивный вызов функции для дочерней ссылки.\n",
    "\n",
    "        crawl_and_extract(url, url)                                                    # Начало обхода и извлечения с указанного URL.\n",
    "\n",
    "    return output_zip_filename                                                         # Возврат пути к ZIP-архиву."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():                                                                            # Определение главной функции\n",
    "    url = \"https://pstu.ru/sveden/education/\"                                          # Указание URL для начала обхода.\n",
    "    output_folder = r\"C:\\Users\\79125\\OneDrive\\Рабочий стол\\Учёба ПНИПУ АСУ\\3 семестр\\Интеллектуальный анализ Web данных\\пдф\"   # Обозначение папки сохранения\n",
    "    zip_filename = download_pdf_text(url, output_folder)                               # Вызов функции загрузки PDF и извлечения текста\n",
    "    if zip_filename:\n",
    "        print(f\"Тексты из PDF успешно загружены и сохранены в: {zip_filename}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
